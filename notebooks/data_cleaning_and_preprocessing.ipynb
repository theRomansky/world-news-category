{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-03T18:07:30.678552Z",
     "start_time": "2024-05-03T18:07:28.360391Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "import pickle\n",
    "from sklearn.preprocessing import LabelEncoder"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-03T18:07:30.915447Z",
     "start_time": "2024-05-03T18:07:30.679224Z"
    }
   },
   "cell_type": "code",
   "source": "df = pd.read_csv('../data/news.csv')",
   "id": "a386df171a7e076a",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-03T18:07:30.925567Z",
     "start_time": "2024-05-03T18:07:30.916489Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Remove the 'date' column from the DataFrame\n",
    "df = df.drop('date', axis=1)"
   ],
   "id": "79aca7084d4b2571",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-03T18:07:30.950154Z",
     "start_time": "2024-05-03T18:07:30.926470Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Select rows with duplicate values in the 'text' column, keeping all occurrences\n",
    "duplicated = df[df.duplicated(subset=['text'], keep=False)]"
   ],
   "id": "f21d9bd9e082086c",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-03T18:07:30.961755Z",
     "start_time": "2024-05-03T18:07:30.951018Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Remove duplicate rows based on the 'text' column\n",
    "df = df.drop_duplicates(subset=['text'])"
   ],
   "id": "7f54aacbb394b66e",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-03T18:07:30.976323Z",
     "start_time": "2024-05-03T18:07:30.962586Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Remove rows with any missing values\n",
    "df = df.dropna(how='any')"
   ],
   "id": "2462f083620f4a5e",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-03T18:07:31.308988Z",
     "start_time": "2024-05-03T18:07:30.977220Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load the English language model from spaCy\n",
    "nlp = spacy.load('en_core_web_sm')"
   ],
   "id": "5615e2d672d28920",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-03T18:07:31.312404Z",
     "start_time": "2024-05-03T18:07:31.310199Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define a function to process text using spaCy\n",
    "def process_text(text):\n",
    "    # Tokenize the text using spaCy\n",
    "    doc = nlp(text)\n",
    "    # Extract lemmatized tokens, excluding punctuation tokens\n",
    "    return [token.lemma_ for token in doc if not token.is_punct]"
   ],
   "id": "ee5bbdeb85fbc5c8",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-03T18:19:32.242404Z",
     "start_time": "2024-05-03T18:07:31.313413Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Process the text in the DataFrame column 'text' using the defined function\n",
    "processed_corpus = [process_text(text) for text in df['text']]"
   ],
   "id": "18bdd44df2e0f25e",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-03T18:19:32.255802Z",
     "start_time": "2024-05-03T18:19:32.244891Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Encode the labels using LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "labels_encoded = label_encoder.fit_transform(df['label'])"
   ],
   "id": "92e2cb520435c5d9",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-03T18:19:32.670801Z",
     "start_time": "2024-05-03T18:19:32.256731Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Save the processed corpus as a pickle file\n",
    "with open('../data/processed_corpus.pkl', 'wb') as f:\n",
    "    pickle.dump(processed_corpus, f)"
   ],
   "id": "87c35d8990b9438a",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-03T18:19:32.674977Z",
     "start_time": "2024-05-03T18:19:32.671798Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Save the encoded labels as a pickle file\n",
    "with open('../data/labels.pkl', 'wb') as f:\n",
    "    pickle.dump(labels_encoded, f)"
   ],
   "id": "d330e59861330efb",
   "outputs": [],
   "execution_count": 12
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
